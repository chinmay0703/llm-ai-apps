# -*- coding: utf-8 -*-
"""üìù Rag.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gW4wPJKGh7_M1qQVQVgG2erH6v5jTWaR
"""

!apt update && apt install -y curl git

!curl -fsSL https://ollama.com/install.sh | sh

!ollama pull llama3

!pkill -f ngrok  # Kills all ngrok processes
!fuser -k 8501/tcp  # Kills any process using port 6000 (or use 5000 if needed)
# Install required libraries
OLLAMA_API_URL = "http://127.0.0.1:11434"
!nohup ollama serve > /dev/null 2>&1 &

!pip install streamlit PyPDF2 requests python-docx

!pip install pyngrok

from pyngrok import ngrok

# Replace with your ngrok auth token
NGROK_AUTH_TOKEN = "2WG8G2YZNV9jofWBKu5B2E6hA3Q_719vVw9PLU1SwQLwCtcNd"

# Set authentication token
ngrok.set_auth_token(NGROK_AUTH_TOKEN)
print("‚úÖ ngrok Auth Token Set!")

public_url = ngrok.connect(8501).public_url
print(f"üöÄ Streamlit App is running at: {public_url}")

import requests

OLLAMA_API_URL = "http://127.0.0.1:11434/api/generate"

headers = {"Content-Type": "application/json"}
payload = {
    "model": "llama3",
    "prompt": "What is the capital of France?",
    "stream": False
}

response = requests.post(OLLAMA_API_URL, json=payload, headers=headers)

if response.status_code == 200:
    print("‚úÖ Response from Ollama:", response.json()["response"])
else:
    print(f"‚ùå Error from Ollama: {response.status_code}, {response.text}")

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import PyPDF2
# import requests
# import tempfile
# import os
# 
# OLLAMA_URL = "http://127.0.0.1:11434/api/generate"
# # Streamlit UI
# st.set_page_config(page_title="Chat with PDF (Llama 3)", layout="wide")
# st.title("üìÑ Chat with Your PDF (Llama 3)")
# st.caption("Upload a PDF and ask questions about its content!")
# 
# uploaded_file = st.file_uploader("üìÇ Upload a PDF", type=["pdf"])
# 
# def extract_text_from_pdf(pdf_path):
#     text = ""
#     with open(pdf_path, "rb") as f:
#         reader = PyPDF2.PdfReader(f)
#         for page in reader.pages:
#             text += page.extract_text() or ""  # Handle NoneType
#     return text.strip()
# 
# if uploaded_file:
#     st.success(f"‚úÖ Uploaded: {uploaded_file.name}")
# 
#     with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as temp_file:
#         temp_file.write(uploaded_file.read())
#         temp_pdf_path = temp_file.name
# 
#     pdf_text = extract_text_from_pdf(temp_pdf_path)
#     os.remove(temp_pdf_path)
# 
#     if pdf_text:
#         st.info("üìÑ PDF text extracted successfully!")
#         with st.expander("üîç View Extracted Text"):
#             st.text_area("PDF Content", pdf_text[:1000] + "..." if len(pdf_text) > 1000 else pdf_text, height=200)
# 
#         question = st.text_input("üí° Ask a question about the document")
# 
#         if question:
#             st.info("ü§ñ Sending question to Llama 3...")
# 
#             ollama_payload = {
#                 "model": "llama3",
#                 "prompt": f"Context: {pdf_text}\n\nQuestion: {question}\n\nAnswer:",
#                 "stream": False
#             }
#             response = requests.post(OLLAMA_URL, json=ollama_payload)
# 
#             if response.status_code == 200:
#                 result = response.json().get("response", "‚ö†Ô∏è No response from Llama 3.")
#                 st.subheader("üìå Answer:")
#                 st.write(result)
#             else:
#                 st.error("‚ö†Ô∏è Failed to get response from Llama 3. Is Ollama running?")
#

!streamlit run app.py &

